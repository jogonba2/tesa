{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Meeting 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To check if the ancestors (category graph) and the value intersections (infobox graph) are complementary.\n",
    "* To separate group/individual information in the input for BART.\n",
    "* Experiments for reducing the scores for negative candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis import network as net\n",
    "import itertools\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from networkx.algorithms.shortest_paths import shortest_path as get_shortest_path\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "import modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are the ancestors and the intersections complementary?\n",
    "\n",
    "\"61.68% of the entity tuples have not got intersections in the 1-hop of the infobox graph\"\n",
    "\n",
    "| Entity tuple | Infobox | Category |\n",
    "| --- | --- | --- |\n",
    "| (A, B) | ✅ | ❌ |\n",
    "| ... | | |\n",
    "| (Y, Z) | ❌ | ✅ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tesa_information(path):\n",
    "    with open(path, \"rb\") as fr:\n",
    "        modeling_task = pkl.load(fr)\n",
    "    \n",
    "    entities = []\n",
    "    aggregations = []\n",
    "    gold_standards = []\n",
    "    types = []\n",
    "    \n",
    "    # modeling_task.test_loader: \n",
    "    for ranking_task in list(itertools.chain(*[modeling_task.train_loader,\n",
    "                                               modeling_task.valid_loader,\n",
    "                                               modeling_task.test_loader])):\n",
    "        aggregations.append([])\n",
    "        gold_standards.append([])\n",
    "        entities.append(ranking_task[0][0][\"entities\"])\n",
    "        types.append(ranking_task[0][0][\"entities_type\"])\n",
    "        for (inp, trg) in ranking_task:\n",
    "            gold_standards[-1].extend(trg)\n",
    "            aggregations[-1].extend(inp[\"choices\"])\n",
    "    \n",
    "    return entities, aggregations, gold_standards, types\n",
    "\n",
    "def get_hops(entity, infobox_graph, hops=1):\n",
    "    hops_map = {0: set([entity])}\n",
    "    for i in range(1, hops + 1):\n",
    "        hops_map[i] = set([])\n",
    "        if entity not in infobox_graph:\n",
    "            continue\n",
    "        for node in hops_map[i-1]:\n",
    "            successors = set([successor for successor in infobox_graph.successors(node)\n",
    "                              if successor and \"WP:\" not in successor])\n",
    "            hops_map[i] = hops_map[i].union(successors)\n",
    "    \n",
    "    if entity in infobox_graph:\n",
    "        hops_map[\"all\"] = set.union(*list(hops_map.values()))\n",
    "    else:\n",
    "        hops_map[\"all\"] = hops_map[0]\n",
    "    return hops_map\n",
    "\n",
    "def get_depth_intersection(intersection, entities_hops):\n",
    "    depth_intersection = []\n",
    "    for node in intersection:\n",
    "        sum_depths = 0\n",
    "        for entity in entities_hops:\n",
    "            for depth in entities_hops[entity]:\n",
    "                if depth != \"all\" and node in entities_hops[entity][depth]:\n",
    "                    sum_depths += depth\n",
    "                    break\n",
    "        depth_intersection.append((node, sum_depths))\n",
    "    return sorted(list(set(depth_intersection)), key=lambda x: x[1])\n",
    "                        \n",
    "    \n",
    "def infobox_value_intersection(aggregatable_entities, infobox_graph, hops=1, topk=10):\n",
    "    \"\"\"\n",
    "    Given a tuple of entities\n",
    "        1) Computes the successors of each entity until a maximum depth *hops*.\n",
    "        2) Intersects all successors (common successors)\n",
    "        3) Sorts the common successors by sum of distances to the entities and pick the $k$ lowest.\n",
    "    \"\"\"\n",
    "    \n",
    "    intersections = {}\n",
    "    \n",
    "    for entities in aggregatable_entities:\n",
    "        # 1)\n",
    "        entities_hops = {entity: get_hops(entity, infobox_graph, hops) for entity in entities}\n",
    "        # 2)\n",
    "        all_hops = [entities_hops[entity][\"all\"] for entity in entities_hops]\n",
    "        intersection = set.intersection(*all_hops)\n",
    "        # 3)\n",
    "        depth_intersections = get_depth_intersection(intersection, entities_hops)[:topk]\n",
    "\n",
    "        intersections[tuple(entities)] = [k for k, _ in depth_intersections]\n",
    "    \n",
    "    return intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./knowledge_graphs/infobox_graph_depth-3.pkl\", \"rb\") as fr:\n",
    "    infobox_graph = pkl.load(fr)\n",
    "    \n",
    "with open(\"./knowledge_graphs/6_lowest_common_ancestors_graph.pkl\", \"rb\") as fr:\n",
    "    ancestors = pkl.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./context-dependent-same-type_50-25-25_rs24_bs4_cf-v0_tf-v2.pkl\"\n",
    "aggregatable_entities, candidates, gold_standards, types = get_tesa_information(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_analysis(intersections):\n",
    "    statistics = {\"empty_intersections\": 0}\n",
    "    statistics[\"empty_intersections\"] = len([k for k in list(intersections.values()) if not k]) \\\n",
    "                                        / len(intersections)\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections_1 = infobox_value_intersection(aggregatable_entities, infobox_graph, hops=1, topk=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregatable_entities = set([tuple(ae) for ae in aggregatable_entities])\n",
    "h = {\"infobox\": 0, \"category\": 0, \"all\": 0, \"any\": 0, \"none\": 0}\n",
    "\n",
    "for entities in aggregatable_entities:\n",
    "    inters = intersections_1[tuple(entities)]\n",
    "    lca = ancestors[tuple(entities)]\n",
    "    \n",
    "    if inters or lca:\n",
    "        h[\"any\"] += 1\n",
    "        if inters:\n",
    "            h[\"infobox\"] += 1\n",
    "        if lca:\n",
    "            h[\"category\"] += 1\n",
    "    \n",
    "        if inters and lca:\n",
    "            h[\"all\"] += 1\n",
    "        \n",
    "    else:\n",
    "        h[\"none\"] += 1\n",
    "\n",
    "#for key in h:\n",
    "#    print(key, \":\", h[key] / len(aggregatable_entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentages over unique entity tuples\n",
    "\n",
    "| Infobox | Category | All | Any | None |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 38.32% | 80.84% | 38.10% | 81.06% | 18.94% |\n",
    "\n",
    "The number of entity tuples that have information of both graphs is very similar to the infobox graph (minimum) and the number of entity tuples that have information of at least one of them is very similar to the category graph (maximum). Basically, the set of entities that have intersections at the 1-hop of the infobox graph is $\\approx$ a subset of the set of entities that have lowest common ancestors in the category graph.\n",
    "\n",
    "| Entity tuple | Infobox | Category |\n",
    "| --- | --- | --- |\n",
    "| (A, B) | ✅ | ✅ |\n",
    "| ... | | |\n",
    "| (Y, Z) | ❌ | ✅ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities with ancestors: 1080\n",
      "Entities with infobox: 512\n",
      "Len intersection: 509\n"
     ]
    }
   ],
   "source": [
    "entities_with_ancestors = set([ent for ent, _ in ancestors.items() if ancestors[ent]])\n",
    "entities_with_infobox = set([ent for ent, _ in intersections_1.items() if intersections_1[ent]])\n",
    "print(\"Entities with ancestors:\", len(entities_with_ancestors))\n",
    "print(\"Entities with infobox:\", len(entities_with_infobox))\n",
    "print(\"Len intersection:\", len(entities_with_ancestors.intersection(entities_with_infobox)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separators for group/individual information\n",
    "\n",
    "I considered the backgrounds of the entities as individual information, and as group information the ancestors of the category graph, the value intersections of the infobox graph and the context. I considered the set of entities as a \"query\" block:\n",
    "\n",
    "> &lt;s>\n",
    "<br>**(S)** $B_1$ ... $B_N$ **<single/group sep>**\n",
    "<br>**(G)** $E_1$, ... and $E_N$ are related to: $A_1$, ... ,$A_P$, $I_1$, ... and $I_Q$ **<graph/article sep>**\n",
    "<br>**(G)** $T: C$ **<group/query sep>**\n",
    "<br>**(Q)** $E_1$, ..., $E_N$\n",
    "<br>&lt;/s>\n",
    "\n",
    "\n",
    "<single/group_sep> = \"µ\"\n",
    "<br><graph/article sep> = \".\" in SGGQ-1 and \"§\" in SGGQ-2\n",
    "<br><group/query sep> = \"£\"\n",
    "\n",
    "\n",
    "| System | MAP | R@10 | MRR |\n",
    "| -- |  -- | -- | -- |\n",
    "| BCE | 83.07 | 93.02 | 93.90 |\n",
    "| AIBCE (I: 1-hop, k=all, A: k=6) | 83.25 | **93.40** | 94.55 |\n",
    "| SGGQ-1 | **83.65** | 92.58 | **95.12** |\n",
    "| SGGQ-2 | 83.48 | 92.52 | 94.73 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing the scores for negative candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we focused on using the knowledge graphs for ranking higher the gold aggregations, but these experiments are focused on ranking lower the distractors.\n",
    "\n",
    "Idea: to use symbolic information extracted from the knowledge graphs as candidates during training. Three ways (from the previous meeting):\n",
    "\n",
    "1. $C^+$ = {G, $S^+$}, $C^-$ = N\n",
    "2. $C^+$ = {G, $S^+$}, $C^-$ = {N, $S^-$} \n",
    "3. $C^+_1$ = {G, $S^+$}, $C^-_1$ = {N, $S^-$} and $C^+_2$ = G, $C^-_2$ = N; alternate them during training.\n",
    "\n",
    "\n",
    "Experimental details:\n",
    "\n",
    "* $C^-$ are not used in the generative setup, so, in this case, I use only $C^+$ = {G, $S^+$} (some idea to integrate $C^-$ in the training process? [Unlikelihood](https://arxiv.org/pdf/1908.04319.pdf)).\n",
    "\n",
    "\n",
    "* I didn't use any information from the graphs in the input (input format: BCE).\n",
    "\n",
    "\n",
    "| System | MAP | R@10 | MRR |\n",
    "| --- | --- | --- | --- |\n",
    "| Generative ($C^{+}$ $=$ {$G$, $A$})| 81.58 | 92.05 | 92.83 |\n",
    "| Generative ($C^{+}$ $=$ {$G$, $I$})| 83.20 | 92.77 | 94.46 |\n",
    "| Generative ($C^{+}$ $=$ {$G$, $A$, $I$})| 81.58 | 92.40 | 92.55 |\n",
    "| Disc-1 | | | |\n",
    "| Disc-2 | | | |\n",
    "| Disc-3 | | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation statistics of the training set, the validation and test sets are not modified.\n",
    "\n",
    "| System | # Pos | # Neg |\n",
    "| --- | --- | --- |\n",
    "| Generative | 2303 | 18289 |\n",
    "| Generative ($S^{+}=A$)| 6545 | 14047 |\n",
    "| Generative ($S^{+}=I$)| 3679 | 16913 |\n",
    "| Generative ($S^{+}$ $=$ {$A$, $I$})| 7420 | 13172 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
